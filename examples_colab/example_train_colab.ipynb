{"cells":[{"cell_type":"markdown","source":["# Example: Train Stardist Model\n","\n","This example file shows how to train a stardist model using a Google Colab runtime. Google Colab is optimized for using files saved to a Google Drive. The training dataset should therefore be uploaded to a Google Drive.\n","\n","## 1. Setting up\n","\n"],"metadata":{"id":"IAs-eEs6Lqtc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"jG__6RyL3snh"},"outputs":[],"source":["%pip install stardist"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xA7hvOj_PLhp"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"id":"dl8uHgK57MKb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pF2l5qVi3uXk"},"source":["# New section"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lBEjIsQ7Nojf"},"outputs":[],"source":["from __future__ import print_function, unicode_literals, absolute_import, division\n","import sys\n","import numpy as np\n","import matplotlib\n","matplotlib.rcParams[\"image.interpolation\"] = 'none'\n","import matplotlib.pyplot as plt\n","import datetime\n","\n","import tensorflow as tf\n","\n","from glob import glob\n","from tqdm import tqdm\n","from tifffile import imread\n","from csbdeep.utils import Path, normalize\n","\n","from stardist import fill_label_holes, random_label_cmap, calculate_extents, gputools_available\n","from stardist import Rays_GoldenSpiral\n","from stardist.matching import matching, matching_dataset\n","from stardist.models import Config3D, StarDist3D, StarDistData3D\n","%load_ext tensorboard"]},{"cell_type":"markdown","metadata":{"id":"EokE4kod3u5J"},"source":["# New section"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UED9gs0yONVC"},"outputs":[],"source":["np.random.seed(66)\n","lbl_cmap = random_label_cmap()"]},{"cell_type":"markdown","metadata":{"id":"P8htWjftOUcb"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_dUSSNP4OU34"},"outputs":[],"source":["X = sorted(glob(\"/content/drive/MyDrive/imageAnalysis/X/*.tif\"))\n","Y = sorted(glob(\"/content/drive/MyDrive/imageAnalysis/y/*.tif\"))\n","\n","#assert all(Path(x).name==Path(y).name for x,y in zip(X,Y))\n","\n","X.sort()\n","Y.sort()\n","\n","print(X)\n","print(Y)\n","\n","X = list(map(imread,X))\n","Y = list(map(imread,Y))\n","\n","\n","n_channel = 1 if X[0].ndim == 3 else X[0].shape[-1]\n","\n","axis_norm = (0,1,2)   # normalize channels independently\n","# axis_norm = (0,1,2,3) # normalize channels jointly\n","if n_channel > 1:\n","    print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 3 in axis_norm else 'independently'))\n","    sys.stdout.flush()\n","\n","X = [normalize(x,1,99.8,axis=axis_norm) for x in tqdm(X)]\n","Y = [fill_label_holes(y) for y in tqdm(Y)]\n","\n","assert len(X) > 1, \"not enough training data\"\n","rng = np.random.RandomState(42)\n","ind = rng.permutation(len(X))\n","n_val = max(1, int(round(0.15 * len(ind))))\n","ind_train, ind_val = ind[:-n_val], ind[-n_val:]\n","X_val, Y_val = [X[i] for i in ind_val]  , [Y[i] for i in ind_val]\n","X_trn, Y_trn = [X[i] for i in ind_train], [Y[i] for i in ind_train]\n","print('number of images: %3d' % len(X))\n","print('- training:       %3d' % len(X_trn))\n","print('- validation:     %3d' % len(X_val))\n","\n","extents = calculate_extents(Y)\n","anisotropy = tuple(np.max(extents) / extents)\n","print('empirical anisotropy of labeled objects = %s' % str(anisotropy))"]},{"cell_type":"code","source":["n_rays = 96\n","\n","# Use OpenCL-based computations for data generator during training (requires 'gputools')\n","use_gpu = True and gputools_available()\n","\n","# Predict on subsampled grid for increased efficiency and larger field of view\n","grid = tuple(1 if a > 1.5 else 4 for a in anisotropy)\n","print(grid)\n","# Use rays on a Fibonacci lattice adjusted for measured anisotropy of the training data\n","rays = Rays_GoldenSpiral(n_rays, anisotropy=anisotropy)\n","\n","conf = Config3D (\n","    rays             = rays,\n","    grid             = grid,\n","    anisotropy       = anisotropy,\n","    use_gpu          = use_gpu,\n","    n_channel_in     = n_channel,\n","    train_epochs    = 750,\n","    # adjust for your data below (make patch size as large as possible)\n","    train_patch_size = (4,32,32),\n","    train_batch_size = 2,\n",")"],"metadata":{"id":"nowXlXUcVJbX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = StarDist3D(conf, name='Test', basedir='models')\n","\n","\n","median_size = calculate_extents(Y, np.median)\n","fov = np.array(model._axes_tile_overlap('ZYX'))\n","print(f\"median object size:      {median_size}\")\n","print(f\"network field of view :  {fov}\")\n","if any(median_size > fov):\n","    print(\"WARNING: median object size larger than field of view of the neural network.\")\n"],"metadata":{"id":"9DajTxgLVROI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def random_fliprot(img, mask, axis=None):\n","    if axis is None:\n","        axis = tuple(range(mask.ndim))\n","    axis = tuple(axis)\n","\n","    assert img.ndim>=mask.ndim\n","    perm = tuple(np.random.permutation(axis))\n","    transpose_axis = np.arange(mask.ndim)\n","    for a, p in zip(axis, perm):\n","        transpose_axis[a] = p\n","    transpose_axis = tuple(transpose_axis)\n","    img = img.transpose(transpose_axis + tuple(range(mask.ndim, img.ndim)))\n","    mask = mask.transpose(transpose_axis)\n","    for ax in axis:\n","        if np.random.rand() > 0.5:\n","            img = np.flip(img, axis=ax)\n","            mask = np.flip(mask, axis=ax)\n","    return img, mask\n","\n","def random_intensity_change(img):\n","    img = img*np.random.uniform(0.6,2) + np.random.uniform(-0.2,0.2)\n","    return img\n","\n","def augmenter(x, y):\n","    \"\"\"Augmentation of a single input/label image pair.\n","    x is an input image\n","    y is the corresponding ground-truth label image\n","    \"\"\"\n","    # Note that we only use fliprots along axis=(1,2), i.e. the yx axis\n","    # as 3D microscopy acquisitions are usually not axially symmetric\n","    x, y = random_fliprot(x, y, axis=(1,2))\n","    x = random_intensity_change(x)\n","    return x, y"],"metadata":{"id":"Jol9nujZVlSD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir /content/models/Test/logs"],"metadata":{"id":"G_Q_1k_jWsOx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.train(X_trn, Y_trn, validation_data=(X_val,Y_val), augmenter=augmenter)\n","\n","model.optimize_thresholds(X_val, Y_val)\n","\n","Y_val_pred = [model.predict_instances(x, n_tiles=model._guess_n_tiles(x), show_tile_progress=False)[0]\n","              for x in tqdm(X_val)]\n","taus = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n","stats = [matching_dataset(Y_val, Y_val_pred, thresh=t, show_progress=False) for t in tqdm(taus)]\n"],"metadata":{"id":"QrMY1wIwVpma"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}